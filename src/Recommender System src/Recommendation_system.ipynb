{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jOPq78_u8_k"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import collections\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, RobustScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/drive/MyDrive/Final_College_Data.xlsx', index_col=0) \n",
        "data.head() "
      ],
      "metadata": {
        "id": "MPAVfBwEu_MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape\n"
      ],
      "metadata": {
        "id": "ji6Bi617vBvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data['Decision'] =='Accepted']\n",
        "\n",
        "data.shape"
      ],
      "metadata": {
        "id": "li8PRqs3vGpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "8kfcKdoCvJZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = data.univName                 \n",
        "x = data.drop('univName',axis=1) "
      ],
      "metadata": {
        "id": "gbydhWKVvLEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label the University names to perform SMOTE\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "encoded_Y = encoder.transform(y)\n"
      ],
      "metadata": {
        "id": "G0og5VTJvRdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = pd.get_dummies(x)"
      ],
      "metadata": {
        "id": "NsGWzv2Avc7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform over_sampling to balance the dataset\n",
        "smote = SMOTE(sampling_strategy='not majority')\n",
        "X1, Y1 = smote.fit_sample(x1,encoded_Y)\n"
      ],
      "metadata": {
        "id": "dcP_SOMWvfBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the values\n",
        "sc = RobustScaler()       # Robust scaler takes care of outliers as well\n",
        "X = sc.fit_transform(X1)"
      ],
      "metadata": {
        "id": "DTwNA0V2vmMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding of the University Names\n",
        "Y = np_utils.to_categorical(Y1)"
      ],
      "metadata": {
        "id": "gBczA4XAvr7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the train and test set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=42,shuffle=True)\n"
      ],
      "metadata": {
        "id": "0gx473TXvvh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Multi-class Classifier Model\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(400, activation='relu', kernel_initializer='random_normal', input_dim=X_test.shape[1]))\n",
        "classifier.add(Dense(800, activation='relu', kernel_initializer='random_normal'))\n",
        "classifier.add(Dense(100, activation='relu', kernel_initializer='random_normal'))\n",
        "classifier.add(Dense(36, activation='softmax', kernel_initializer='random_normal'))\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "classifier.fit(X_train,Y_train,batch_size=20,epochs=200,verbose=0)\n",
        "eval_model = classifier.evaluate(X_train,Y_train)\n",
        "print(\"Accuracy: \",eval_model[1]) "
      ],
      "metadata": {
        "id": "7rfs2eOhvxmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted class for each test sample\n",
        "\n",
        "y_pred = classifier.predict_classes(X_test)\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "id": "8MvK-YcxwBoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate confusion matrix to see the performance of classifier in classifying correctly\n",
        "\n",
        "cm = confusion_matrix(Y_test.argmax(axis=1),y_pred)\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(cm,annot=False,ax=ax);\n",
        "ax.set_xlabel('Predicted');\n",
        "ax.set_ylabel('Actual');\n",
        "ax.set_title('Confusion Matrix');\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aTgmpU72wFFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Nearest Neighbour classifier and SVM Classifier ##\n"
      ],
      "metadata": {
        "id": "nL0zqbgQxsAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Nearest_Neighbour_classifier(train_input_data,train_output_data,test_input_data,test_output_data):\n",
        "    neighbour_list = []\n",
        "    accuracy_percent = []\n",
        "    for neighbours in range(1,101,5):\n",
        "        clf = neighbors.KNeighborsClassifier(neighbours, weights='uniform')\n",
        "        clf.fit(train_input_data, train_output_data)\n",
        "        predicted_output = clf.predict(test_input_data)\n",
        "        if isinstance(predicted_output,list) ==False:\n",
        "            predicted_output = predicted_output.tolist()\n",
        "        if isinstance(test_output_data,list) ==False:\n",
        "            test_output_data = test_output_data.tolist()\n",
        "        error_list = []\n",
        "        for i in range(len(test_output_data)):\n",
        "            cur_univ_similarities =  similar_univs[similar_univs['univName'] == predicted_output[i]]\n",
        "            cur_univ_similarity_list = cur_univ_similarities.values.tolist()\n",
        "            cur_univ_similarity_list = [item for sublist in cur_univ_similarity_list for item in sublist]\n",
        "            if test_output_data[i] in cur_univ_similarity_list[1:]:\n",
        "                error_list.append(0)\n",
        "            else:\n",
        "                error_list.append(1)\n",
        "        neighbour_list.append(neighbours)\n",
        "        accuracy_percent.append(100 -((sum(error_list)/float(len(error_list))) * 100))\n",
        "    neighbour_list = np.array(neighbour_list)\n",
        "    accuracy_percent = np.array(accuracy_percent)\n",
        "    plt.plot(neighbour_list,accuracy_percent)\n",
        "    plt.xlabel('Number of nearest neighbors')\n",
        "    plt.ylabel('Percent of accuracy')\n",
        "    plt.title('Varation of accuracy with nearest neighbours')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"knn1.png\")\n",
        "    plt.show()\n",
        "    return predicted_output"
      ],
      "metadata": {
        "id": "xWbgreF1wQZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SVM_classifier(train_input_data,train_output_data,test_input_data,test_output_data):\n",
        "    clf = svm.SVC()\n",
        "    clf.fit(train_input_data,train_output_data)\n",
        "    predicted_output = clf.predict(test_input_data)\n",
        "    error_list = []\n",
        "    predicted_output = predicted_output.tolist()\n",
        "    test_output_data  = test_output_data.tolist()\n",
        "    for i in range(len(test_output_data)):\n",
        "        cur_univ_similarities =  similar_univs[similar_univs['univName'] == predicted_output[i]]\n",
        "        cur_univ_similarity_list = cur_univ_similarities.values.tolist()\n",
        "        cur_univ_similarity_list = [item for sublist in cur_univ_similarity_list for item in sublist]\n",
        "        if test_output_data[i] in cur_univ_similarity_list[1:]:\n",
        "            error_list.append(0)\n",
        "        else:\n",
        "            error_list.append(1)\n",
        "    return predicted_output\n"
      ],
      "metadata": {
        "id": "ccNVNLJtwaVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pandas.read_csv('processed_data.csv')\n",
        "data = data.drop('Unnamed: 0',1)\n",
        "data = data.drop('Unnamed: 0.1',1)"
      ],
      "metadata": {
        "id": "QkE9psPvwf3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_univs = pandas.read_csv('similar_universities.csv')\n",
        "random_indices = permutation(data.index)\n",
        "test_cutoff = math.floor(len(data)/5)\n",
        "test = data.loc[random_indices[1:test_cutoff]]\n",
        "train = data.loc[random_indices[test_cutoff:]]\n",
        "train_output_data = train['univName']\n",
        "train_input_data = train\n",
        "train_input_data = train_input_data.drop('univName',1)\n",
        "test_output_data = test['univName']\n",
        "test_input_data = test\n",
        "test_input_data = test_input_data.drop('univName',1)"
      ],
      "metadata": {
        "id": "PAb_dIYWwnFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = Random_Forest_classifier(train_input_data,train_output_data,test_input_data,test_output_data)\n",
        "output = SVM_classifier(train_input_data,train_output_data,test_input_data,test_output_data)"
      ],
      "metadata": {
        "id": "CuAVFuY-wpQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collaborative Filtering Based Recommender System ##"
      ],
      "metadata": {
        "id": "RRwVIighxjht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import TfidfVector from sklearn.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "def create_similarity_matrix(new_description, overall_descriptions):\n",
        "#Append the new description to the overall set.\n",
        "      overall_descriptions.append(new_description)\n",
        "        # Define a tfidf vectorizer and remove all stopwords.\n",
        "      tfidf = TfidfVectorizer(stop_words=\"english\")\n",
        "        #Convert tfidf matrix by fitting and transforming the data.\n",
        "      tfidf_matrix = tfidf.fit_transform(overall_descriptions)\n",
        "        # output the shape of the matrix.\n",
        "      tfidf_matrix.shape\n",
        "        # calculating the cosine similarity matrix.\n",
        "      cosine_sim = linear_kernel(tfidf_matrix,tfidf_matrix)\n",
        "      return cosine_sim"
      ],
      "metadata": {
        "id": "ot_4P5rswvfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(new_description,overall_descriptions):\n",
        "# create the similarity matrix\n",
        "  cosine_sim = create_similarity_matrix(new_description,overall_descriptions)\n",
        "# Get pairwise similarity scores of all the students with new student.\n",
        "  sim_scores = list(enumerate(cosine_sim[-1]))\n",
        "# Sort the descriptions based on similarity score.\n",
        "  sim_scores = sorted(sim_scores,key =lambda x:x[1],reverse= True )\n",
        "# Get the scores of top 10 descriptions.\n",
        "  sim_scores = sim_scores[1:10]\n",
        "# Get the student indices.\n",
        "  indices = [i[0]for i in sim_scores]\n",
        "  return data.iloc[indices]"
      ],
      "metadata": {
        "id": "Pmbovk9VxDJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_description = pd.Series('physics science 78')\n",
        "get_recommendations(new_description,descriptions)"
      ],
      "metadata": {
        "id": "yElHRqYvxOXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tNR8fAnbxSKW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}